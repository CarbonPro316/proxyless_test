# Builtin Configurations(DO NOT CHANGE THESE CONFIGURATIONS unlesee you know exactly what you are doing)
enable_modelarts: True
# url for modelarts
data_url: ""
train_url: ""
checkpoint_url: ""
# path for local
data_path: "/cache/data"
output_path: "/cache/train"
load_path: "/cache/checkpoint_path"
#device_target: "Ascend"
#目标设备：GPU
device_targer: "GPU"
enable_profiling: False

# ======================================================================================
# common options
num_classes: 1000 
label_smooth_factor: 0.1
device_id: 0

# ======================================================================================
# Training options
epoch_size: 300  
keep_checkpoint_max: 20
save_ckpt_path: "./"
save_checkpoint_epochs: 1
save_checkpoint: True
amp_level: "O3"
is_distributed: True
train_dataset_path: "/cache/data/train"
resume: ""

# Dataset config
train_batch_size: 131
val_batch_size: 125

#learning rate config
lr_init: 0.2
drop_path_prob: 0.0

#optimization config
weight_decay: 0.0001
momentum: 0.9

# ======================================================================================
# Eval options
ckpt_path: ""
eval_dataset_path: ""

# ======================================================================================
# export options
file_name: "proxylessnas_mobile"
file_format: "MINDIR"

---
# Help description for each configuration
enable_modelarts: "Whether training on modelarts default: False"
data_url: "Url for modelarts"
train_url: "Url for modelarts"
data_path: "The location of input data"
output_pah: "The location of the output file"
device_target: "device id of GPU or Ascend. (Default: None)"
enable_profiling: "Whether enable profiling while training default: False"
is_distributed: "distributed training"
resume: "resume training with existed checkpoint"
device_id: "device id"
file_name: "output file name"
file_format: "file format choices [AIR MINDIR ONNX]"
